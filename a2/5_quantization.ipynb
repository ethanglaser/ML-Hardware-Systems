{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ML-HW-SYS/a2/blob/main/5_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"DLNHtJrAqKWo"},"source":["# **5. Quantization**\n"]},{"cell_type":"markdown","metadata":{"id":"h5kS114ooq-0"},"source":["## 5.0 Setup Capabilities"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"zjOhFCIkxVfL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647186591507,"user_tz":240,"elapsed":25787,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"37a038af-0e59-4da2-e007-10e05950b843"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Mount google drive \n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hoEUDK6KxVfM"},"outputs":[],"source":["# Make sure your token is stored in a txt file at the location below.\n","# This way there is no risk that you will push it to your repo\n","# Never share your token with anyone, it is basically your github password!\n","with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n","    token = f.readline().strip()\n","# Use another file to store your github username    \n","with open('/content/gdrive/MyDrive/ece5545/user.txt') as f:\n","    handle = f.readline().strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXP6DjaqxVfM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147724232,"user_tz":300,"elapsed":20363,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"d0a65f16-441f-42b4-e2a2-3ada8630ace0"},"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/gdrive/MyDrive/ece5545’: File exists\n","/content/gdrive/MyDrive/ece5545\n","fatal: destination path 'a2-ethanglaser' already exists and is not an empty directory.\n","/content/gdrive/MyDrive/ece5545/a2-ethanglaser\n","M\t1_audio_preprocessing.ipynb\n","M\t2_size_estimator_and_profiler.ipynb\n","M\t3_training_and_analysis.ipynb\n","M\t4_model_conversion.ipynb\n","M\t5_quantization.ipynb\n","M\t6_pruning.ipynb\n","M\tsrc/train_val_test_utils.py\n","Already on 'main'\n","Your branch is up to date with 'origin/main'.\n","Already up to date.\n","/content/gdrive/MyDrive/ece5545\n"]}],"source":["# Clone your github repo\n","YOUR_TOKEN = token\n","YOUR_HANDLE = handle\n","BRANCH = \"main\"\n","\n","%mkdir /content/gdrive/MyDrive/ece5545\n","%cd /content/gdrive/MyDrive/ece5545\n","!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a2-{YOUR_HANDLE}.git\n","%cd /content/gdrive/MyDrive/ece5545/a2-{YOUR_HANDLE}\n","!git checkout {BRANCH}\n","!git pull\n","%cd /content/gdrive/MyDrive/ece5545\n","\n","PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a2-{YOUR_HANDLE}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eDWK1EVxVfN"},"outputs":[],"source":["# This extension reloads all imports before running each cell\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"4w6cL9l3xVfO"},"source":["Please verify the cell below prints out the github repository."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQSeJ7fExVfP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147724234,"user_tz":300,"elapsed":18,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"b60889c9-5d85-421a-88f8-7387fb5fdb42"},"outputs":[{"output_type":"stream","name":"stdout","text":["1_audio_preprocessing.ipynb\t     5_quantization.ipynb\t      README.md\n","2_size_estimator_and_profiler.ipynb  6_pruning.ipynb\t\t      src\n","3_training_and_analysis.ipynb\t     arduino_nano_33_ble_tutorial.md  tests\n","4_model_conversion.ipynb\t     images\n"]}],"source":["!ls '{PROJECT_ROOT}'"]},{"cell_type":"markdown","metadata":{"id":"MM5gV8CNqd-s"},"source":["### Install required packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLE4Xmakoq-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147729729,"user_tz":300,"elapsed":5504,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"38462135-0e9d-49da-b282-d121c18658c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n","Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchaudio) (3.10.0.2)\n"]}],"source":["# Install libraries\n","!pip install tqdm\n","!pip install torchaudio"]},{"cell_type":"markdown","metadata":{"id":"55zgRQWVqu6n"},"source":["### Import code dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pk0tnhRoq-5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147738547,"user_tz":300,"elapsed":8826,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"87125601-6c91-45ab-c4b5-0ba1995fab61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model folders are created, \n","PyTorch models will be saved in /content/gdrive/MyDrive/ece5545/models/torch_models, \n","ONNX models will be saved in /content/gdrive/MyDrive/ece5545/models/onnx_models, \n","TensorFlow Saved Models will be saved in /content/gdrive/MyDrive/ece5545/models/tf_models, \n","TensorFlow Lite models will be saved in /content/gdrive/MyDrive/ece5545/models/tflite_models, \n","TensorFlow Lite Micro models will be saved in /content/gdrive/MyDrive/ece5545/models/micro_models.\n"]}],"source":["# Import libraries \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import numpy as np\n","import copy\n","import os\n","\n","import sys\n","\n","# Adding assignment 2 to the system path\n","# -- make sure this matches your git directory\n","sys.path.insert(0, PROJECT_ROOT)\n","\n","# Import data_proc to use data processing functions\n","import src.data_proc as data_proc\n","\n","# Import constants to use constants defined for training\n","from src.constants import *\n","\n","# Set random seed\n","# Make sure the shuffling and picking is deterministic\n","# Note that different value of random_seed may change rate of variation in loss/accuracy during training\n","# Using the same random seed value every time you rerun the notebook will \n","# reproduce the training and testing results  \n","random_seed = RANDOM_SEED\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","np.random.seed(random_seed)"]},{"cell_type":"markdown","metadata":{"id":"qPNyurTpoq_C"},"source":["## 5.1 Define Quantization Functions\n","\n","There are some test cases in the `tests` folder to verify basic functionality of your implemented functions--these will be run automatically every time you check in your code. Additionally, we've left some simple tests in this notebook as well for you to try things out.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hTaCRrjeJgBR"},"source":["#### TODO 0: Implement the backward pass of `ste_round` function in `src/quant.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQy4ffsVPc8o"},"outputs":[],"source":["# add a test if you like. There's already one under tests/"]},{"cell_type":"markdown","metadata":{"id":"zOvGVC1CxVfR"},"source":["\n","#### TODO 1: Implement the `linear_quantize` function in `src/quant.py`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXUIpaEMoq_C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147738952,"user_tz":300,"elapsed":432,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"4376bb61-c4b5-4b4b-fbea-ea770c90d264"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 0., 0., 1.])\n"]}],"source":["from src.quant import linear_quantize\n","\n","# Mini test case for linear_quantize\n","with torch.no_grad():\n","    x = torch.tensor([2, -0.5, 0., 1.])\n","    scale = 1\n","    zero = 0\n","    y = linear_quantize(x, scale, zero)\n","    print(y) # y should be [2, 0, 0, 1]"]},{"cell_type":"markdown","metadata":{"id":"bvZ9zUycxVfR"},"source":["#### TODO 2: Implement the `SymmetricQuantFunction` forward function in `src/quant.py`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxiSaE_dxVfR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147739186,"user_tz":300,"elapsed":237,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"554583ea-64cd-41c7-f36d-52c29de8c26e"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., -0., 0., 1.], grad_fn=<SymmetricQuantFunctionBackward>)\n","tensor([2., -0., 0., 2.])\n"]}],"source":["from src.quant import SymmetricQuantFunction\n","\n","quant_f = SymmetricQuantFunction.apply\n","\n","x = torch.tensor([2, -0.5, 0., 1.])\n","x.requires_grad = True\n","bw = 2\n","y = quant_f(x, bw, scale, zero)\n","(y ** 2).sum().backward()\n","\n","print(y)      # [1, 0, 0, 1]\n","print(x.grad) # [2, 0, 0, 2]"]},{"cell_type":"markdown","metadata":{"id":"7M_CmQ5-xVfS"},"source":["#### TODO 3: Implement the `AsymmetricQuantFunction` forward function in `src/quant.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQBP2WWtxVfS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147739187,"user_tz":300,"elapsed":14,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"85729e2a-2466-4cc8-ef7a-7e14b7d9a051"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., -0., 0., 1.], grad_fn=<AsymmetricQuantFunctionBackward>)\n","tensor([4., -0., 0., 2.])\n"]}],"source":["from src.quant import AsymmetricQuantFunction\n","\n","quant_f = AsymmetricQuantFunction.apply\n","\n","x = torch.tensor([2, -0.5, 0., 1.])\n","x.requires_grad = True\n","bw = 2\n","y = quant_f(x, bw, scale, zero)\n","(y ** 2).sum().backward()\n","\n","print(y)      # [2, 0, 0, 1]\n","print(x.grad) # [4, 0, 0, 2]"]},{"cell_type":"markdown","metadata":{"id":"EClG-iStxVfS"},"source":["#### TODO 4: Finish the Implement of `get_quantization_params` function in `src/quant.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtjXI5zjxVfS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147739188,"user_tz":300,"elapsed":9,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"c8d943a2-bab6-4095-83c4-70dd64964c39"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor(0.2857), tensor(0))\n","(tensor(0.1667), tensor(3.))\n"]}],"source":["from src.quant import QConfig\n","\n","qconfig = QConfig(quant_bits=4, is_symmetric=True)\n","print(qconfig.get_quantization_params(x.min(), x.max())) # Expect: 0.2857, 0\n","\n","qconfig = QConfig(quant_bits=4, is_symmetric=False)\n","print(qconfig.get_quantization_params(x.min(), x.max())) # Expect: 0.1667, 3."]},{"cell_type":"markdown","metadata":{"id":"MLT8xONCoq_D"},"source":["#### TODO 5: Implement the `quantize_weights_bias` function in `src/quant.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1athpSf1oq_D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147739471,"user_tz":300,"elapsed":288,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"8f256242-d88d-424e-82ac-ab0e5bc5b7df"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 7., -2.,  0.,  3.])\n","tensor([ 7., -3.,  0.,  4.])\n"]}],"source":["from src.quant import quantize_weights_bias, QConfig\n","\n","qconfig = QConfig(quant_bits=4, is_symmetric=True)\n","\n","w1 = nn.Parameter(torch.tensor([2, -0.5, 0., 1.]))\n","qw1 = quantize_weights_bias(w1, qconfig)\n","print(qw1.data) # [7, -2, 0, 3]\n","\n","w2 = nn.Parameter(torch.tensor([2.5, -1, 0., 1.5]))\n","qw2 = quantize_weights_bias(w2, qconfig)\n","print(qw2.data) # [7, -3, 0, 4]"]},{"cell_type":"markdown","metadata":{"id":"xnpBdnuBoq_E"},"source":["## 5.2 Quantization Function for Linear and Convolution Layer\n","\n","#### TODO 6: Finish the implementation of `conv2d_linear_quantized` function in `src/quant.py`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNN8WiYPoq_E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147739473,"user_tz":300,"elapsed":21,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"2caa4db3-9ddb-41d4-a706-e4f5e9dbb562"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.1000, 2.1000]], grad_fn=<AddmmBackward0>)\n","tensor([[0.9571, 2.1000]], grad_fn=<AddmmBackward0>)\n"]}],"source":["import torch.nn as nn\n","from src.quant import QuantWrapper\n","\n","layer = nn.Linear(2, 2)\n","layer.weight.data = torch.tensor([[0.1, 0.1], [-0.1, 0.1]]).view(2, 2).float()\n","layer.bias.data = torch.tensor([1, 2]).view(*layer.bias.shape).float()\n","x = torch.tensor([[0., 1]])\n","print(layer(x)) # [1.1, 2.1]\n","\n","quant_layer = QuantWrapper(\n","    layer, \n","    QConfig(quant_bits=4, is_symmetric=True), \n","    QConfig(quant_bits=4, is_symmetric=True), \n","    QConfig(quant_bits=4, is_symmetric=True))\n","print(quant_layer(x)) # [0.957, 2.1]\n"]},{"cell_type":"markdown","metadata":{"id":"lax5KDyxoq_F"},"source":["## 5.3 Prepare model for QAT (Quantization Aware Training)"]},{"cell_type":"markdown","metadata":{"id":"yLFhKVStmTbG"},"source":["### Get Audio Processor, Devices, Data Loader, and Model\n","\n","NOTE: This is identical to section 2.2 ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBcLXHHim6ry","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147862539,"user_tz":300,"elapsed":123080,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"f71ee529-e5f2-4c66-bee4-8d9859125c3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Audio_processor created\n","Using cuda to run the training scrpit.\n","Train size: 10556 Val size: 1333 Test size: 1368\n"]},{"output_type":"execute_result","data":{"text/plain":["TinyConv(\n","  (conv_reshape): Reshape(output_shape=(-1, 1, 49, 40))\n","  (conv): Conv2d(1, 8, kernel_size=(10, 8), stride=(2, 2), padding=(5, 3))\n","  (relu): ReLU()\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc_reshape): Reshape(output_shape=(-1, 4000))\n","  (fc): Linear(in_features=4000, out_features=4, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":17}],"source":["# Create audio_processor\n","# DATASET_DIR is defined in constants.py\n","audio_processor = data_proc.AudioProcessor(data_dir=DATASET_DIR)\n","print(\"Audio_processor created\")\n","\n","# Define device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using {device} to run the training scrpit.')\n","\n","# Define data loaders\n","from src.loaders import make_data_loaders\n","data_loaders = make_data_loaders(audio_processor, device)\n","train_loader = data_loaders['training']\n","test_loader = data_loaders['testing']\n","valid_loader = data_loaders['validation']\n","\n","# Create a full precision (float32) TinyConv model\n","from src.networks import TinyConv\n","model_fp32 = TinyConv(model_settings=audio_processor.model_settings, \\\n","    n_input=1, n_output=audio_processor.num_labels)\n","\n","model_fp32"]},{"cell_type":"markdown","metadata":{"id":"P7wcn11MxVfT"},"source":["### Load Pretrained Model for Quantization Aware Finetuning\n","\n","In this notebook, we will load the previously trained 32-bits float model to finetune it in a quantizaiton-aware way. \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_QYYl4oxVfT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147862841,"user_tz":300,"elapsed":323,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"ee50c464-7df8-4a70-a791-58efc43b6192"},"outputs":[{"output_type":"stream","name":"stdout","text":[" fp32_checkpoint.pt\t      '(QAT4bit)quant_0.pt'\n"," fp32_finetune_checkpoint.pt   quant_checkpoint.pt\n"]}],"source":["!ls {TORCH_DIR}"]},{"cell_type":"markdown","metadata":{"id":"ys6gVPF6xVfT"},"source":["### **TODO: Replace the torch_path model with the model you created in the last section.** \n","\n","You can find the name of your file in `TORCH_DIR` under the folder icon to the left. (Or from running the tab above)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"98TcWxPWxVfU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647147873562,"user_tz":300,"elapsed":10724,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"4a74620f-74f6-4e49-9cf4-c197f6488adc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TinyConv(\n","  (conv_reshape): Reshape(output_shape=(-1, 1, 49, 40))\n","  (conv): Conv2d(1, 8, kernel_size=(10, 8), stride=(2, 2), padding=(5, 3))\n","  (relu): ReLU()\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc_reshape): Reshape(output_shape=(-1, 4000))\n","  (fc): Linear(in_features=4000, out_features=4, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":19}],"source":["# TODO: Replace me!\n","torch_path = os.path.join('/content/gdrive/MyDrive/ece5545/', \"tinyconv_float32_init_seed0_90.35%_0.pt\")\n","\n","# Load model\n","model_fp32.load_state_dict(torch.load(torch_path))\n","model_fp32"]},{"cell_type":"markdown","metadata":{"id":"s6RTZp_yoq_F"},"source":["### Define settings for weight and activation quantization "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrTGvZMtoq_F"},"outputs":[],"source":["# We choose 4 bit quantization as an example because accuracy improvements will \n","# be more obvious with 4-bit or lower bit quantization\n","QUANT_BITS = 4\n","# Settings for activations quantization: n-bit asymmetric quantization\n","a_qconfig = QConfig(quant_bits=QUANT_BITS, is_symmetric=False)\n","# Settings for weights quantization: n-bit symmetric quantization\n","w_qconfig = QConfig(quant_bits=QUANT_BITS, is_symmetric=True)\n","# Settings for bias quantization: n-bit symmetric quantization\n","b_qconfig = QConfig(quant_bits=QUANT_BITS, is_symmetric=True)"]},{"cell_type":"markdown","metadata":{"id":"5FD7l9cNoq_F"},"source":["### Prepare quantization aware training model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"capV1g7loq_F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647140046751,"user_tz":300,"elapsed":66,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"b14296b7-4645-4f36-ed6e-48656c1aff31"},"outputs":[{"output_type":"stream","name":"stdout","text":["TinyConv(\n","  (conv_reshape): Reshape(output_shape=(-1, 1, 49, 40))\n","  (conv): QuantWrapper(\n","    (module): Conv2d(1, 8, kernel_size=(10, 8), stride=(2, 2), padding=(5, 3))\n","  \t(activation): quant_bits=4, quant_mode=asymmetric, prev_scale=None, prev_zeropoint=None, prev_min=None, prev_max=None  \n","  \t(weight): quant_bits=4, quant_mode=symmetric, prev_scale=None, prev_zeropoint=None, prev_min=None, prev_max=None  \n","  \t(bias): quant_bits=4, quant_mode=symmetric, prev_scale=None, prev_zeropoint=None, prev_min=None, prev_max=None  \n","  )\n","  (relu): ReLU()\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc_reshape): Reshape(output_shape=(-1, 4000))\n","  (fc): QuantWrapper(\n","    (module): Linear(in_features=4000, out_features=4, bias=True)\n","  \t(activation): quant_bits=4, quant_mode=asymmetric, prev_scale=None, prev_zeropoint=None, prev_min=None, prev_max=None  \n","  \t(weight): quant_bits=4, quant_mode=symmetric, prev_scale=None, prev_zeropoint=None, prev_min=None, prev_max=None  \n","  \t(bias): quant_bits=4, quant_mode=symmetric, prev_scale=None, prev_zeropoint=None, prev_min=None, prev_max=None  \n","  )\n","  (softmax): Softmax(dim=1)\n",")\n"]}],"source":["from src.quant import quantize_model\n","qat_model_nbit = quantize_model(\n","    model_fp32, a_qconfig=a_qconfig, w_qconfig=w_qconfig, b_qconfig=b_qconfig)\n","\n","# Print to see the model prepared for QAT\n","print(qat_model_nbit)"]},{"cell_type":"markdown","metadata":{"id":"SkHtQEQXoq_G"},"source":["##  5.4 Finetuning\n","\n","In this training, we will finetune the 32-bits float pretrained model. The goal is to finetune the weights of the 32-bits float model such that the resulted model will have better accuracy after quantization."]},{"cell_type":"markdown","metadata":{"id":"QvZ9g2QlxVfU"},"source":["### Quantization Aware Finetuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCC9s6dUoq_H","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"error","timestamp":1647148146441,"user_tz":300,"elapsed":11,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"072994d2-7199-465f-d642-e32bfffcc6ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["#batches: 106 \n","#epochs: 30 \n","#total training steps: 3180\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-ed4035b8ec75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Create optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0moptimizer_quant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqat_model_nbit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_quant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'qat_model_nbit' is not defined"]}],"source":["import time\n","from src.train_val_test_utils import train, test\n","from src.train_val_test_utils import create_optimizer\n","\n","\n","def run_training(model, data_loaders, n_epoch, log_interval, optimizer, scheduler=None, \n","                 save_interval=1, resume=True, checkpoint_path=None, verbose=False):\n","    test_loader = data_loaders['testing']\n","    with tqdm(total=n_epoch) as pbar:\n","        completed_epoch = 1\n","        if resume:\n","            try:\n","                #continue training with previous model if one exists\n","                if checkpoint_path is None:\n","                    raise ValueError\n","                checkpoint = torch.load(checkpoint_path)\n","                model.load_state_dict(checkpoint['model_state_dict'])\n","                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","                if scheduler is not None:\n","                    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","                completed_epoch = checkpoint[\"epoch\"] + 1\n","                model.eval()\n","                pbar.update(completed_epoch)\n","            except:\n","                pass\n","\n","        for epoch in range(completed_epoch, n_epoch + 1):\n","            train_iters = len(data_loaders['training'])\n","            train(model, data_loaders, optimizer, epoch, device, verbose)\n","            test(test_loader, model, device, \n","                 epoch=None, loader_type='Test')\n","            \n","            if scheduler is not None:\n","                scheduler.step()\n","            #checkpoint the model every run\n","            if epoch % save_interval == 0 and checkpoint_path is not None:\n","                torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'scheduler_state_dict': scheduler.state_dict() if scheduler is not None else None\n","                }, checkpoint_path)\n","                \n","            # Update epoch pbar\n","            pbar.update(1)\n","\n","\n","verbose = False\n","log_interval = 100\n","num_batches = len(train_loader)\n","n_epoch = 30\n","print(f'#batches: {num_batches} \\n#epochs: {n_epoch} \\n#total training steps: {num_batches * n_epoch}')\n","\n","# Create optimizer\n","optimizer_quant = create_optimizer(model=qat_model_nbit, learning_rate=0.001)\n","print(optimizer_quant.state_dict())\n","\n","checkpoint_path = os.path.join(TORCH_DIR, \"quant_checkpoint.pt\")\n","qat_model_nbit.to(device)\n","# run_training(\n","#     model=qat_model_nbit, data_loaders=data_loaders, \n","#     n_epoch=n_epoch, log_interval=log_interval, \n","#     optimizer=optimizer_quant, scheduler=None, \n","#     resume=False,\n","#     checkpoint_path=checkpoint_path,\n","#     verbose=verbose\n","# )"]},{"cell_type":"markdown","metadata":{"id":"Rj8xFMjqxVfV"},"source":["### Finetune the Float Model\n","\n","For fair comparison, we conduct the same funetuning for the float model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hx9VthdKxVfV","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1647147625624,"user_tz":300,"elapsed":237,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"b1c6109c-8a10-4c26-e667-e962b2f2084c"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-674c2d0efa4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer_fp32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTORCH_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fp32_finetune_checkpoint.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_fp32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_optimizer' is not defined"]}],"source":["# Create optimizer\n","optimizer_fp32 = create_optimizer(model=model_fp32, learning_rate=0.0001)\n","\n","checkpoint_path = os.path.join(TORCH_DIR, \"fp32_finetune_checkpoint.pt\")\n","model_fp32.to(device)\n","run_training(\n","    model=model_fp32, data_loaders=data_loaders, \n","    n_epoch=n_epoch, log_interval=log_interval, \n","    optimizer=optimizer_fp32, scheduler=None, \n","    resume=False,\n","    checkpoint_path=checkpoint_path,\n","    verbose=verbose\n",")"]},{"cell_type":"code","source":["quant_path = os.path.join(TORCH_DIR, \"quant_checkpoint.pt\")\n","qat_model_nbit.load_state_dict(torch.load(quant_path))\n","ft_path = os.path.join(\"/content/gdrive/MyDrive/ece5545/\", \"fp32_finetune_checkpoint.pt\")\n","model_fp32.load_state_dict(torch.load(ft_path))"],"metadata":{"id":"a_spklI-BKj_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jOIj0QUOoq_H"},"source":["## 5.5 Testing"]},{"cell_type":"markdown","metadata":{"id":"95C3tSGNoq_H"},"source":["We will compute the accuracy of the finetuned model in train/val/test set in this section.\n","Note that this is not the final accuracy we want the model to perform well on. \n","We would like our quantized-aware-finetuned model to perform well when quantized into integer. \n","But the training/validation/testing accuracy of these model in quantization simulation model is still worth looking at for sanity checking purpose."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0eFxrBqCoq_H","scrolled":false},"outputs":[],"source":["from src.train_val_test_utils import plot_acc\n","\n","test_time_data_loaders = make_data_loaders(\n","    audio_processor, device, \n","    test_batch_size=1, valid_batch_size=1,\n","    num_workers=0\n",")\n","\n","plot_acc(\n","    test_time_data_loaders['training'], qat_model_nbit, audio_processor, device,\n","    \"Training\", 'n-bit Quantized TinyConv', \"float\")\n","plot_acc(\n","    test_time_data_loaders['validation'], qat_model_nbit, audio_processor, device,\n","    \"Validation\", 'n-bit Quantized TinyConv', \"float\")\n","plot_acc(\n","    test_time_data_loaders['testing'], qat_model_nbit, audio_processor, device,\n","    'Testing', 'n-bit Quantized TinyConv', \"float\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GnJHV-H_xVfV"},"outputs":[],"source":["plot_acc(\n","    test_time_data_loaders['training'], model_fp32, audio_processor, device,\n","    \"Training\", 'FP32 FT TinyConv', \"float\")\n","plot_acc(\n","    test_time_data_loaders['validation'], model_fp32, audio_processor, device,\n","    \"Validation\", 'FP32 FT TinyConv', \"float\")\n","acc = plot_acc(\n","    test_time_data_loaders['testing'], model_fp32, audio_processor, device,\n","    'Testing', 'FP32 FT TinyConv', \"float\")"]},{"cell_type":"markdown","metadata":{"id":"5AehU-BsJgBV"},"source":["## 5.6 Saving the Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"agtFnTuTJgBV"},"outputs":[],"source":["from src.train_val_test_utils import choose_name\n","from src.quant import dequantize_model\n","\n","# Save the qat model\n","qat_model_nbit_float = dequantize_model(qat_model_nbit)\n","file_name = choose_name(\"quant\")\n","# You can also define your own path\n","qat_torch_path = os.path.join(TORCH_DIR, f'(QAT{QUANT_BITS}bit){file_name}.pt')\n","# Save the trained n-bit qat pytorch model to PATH\n","torch.save(qat_model_nbit.state_dict(), qat_torch_path)\n","qat_torch_path"]},{"cell_type":"markdown","metadata":{"id":"mij775vWoq_I"},"source":["## 5.7 Understanding and Evaluate the Effectiveness of Quantization-Aware Training (QAT)"]},{"cell_type":"markdown","metadata":{"id":"oUCINlWNtQB-"},"source":["### Model conversion: Quantized/Float Fine-tuning Model Converted to Integer Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"odKeXjOSoq_I"},"outputs":[],"source":["from src.quant import dequantize_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ssFRMhToq_I"},"outputs":[],"source":["# Convert to quantized model\n","\n","# Quantized integer model of qat_model_nbit (quantized aware finetuning model)\n","int_model_nbit = convert_to_int(\n","    qat_model_nbit, QUANT_BITS, dtype=torch.int32) \n","    \n","# Post quantized model of model_fp32 (full-precision finetuned model)\n","post_quant_model = convert_to_int(\n","    model_fp32, QUANT_BITS, dtype=torch.int32) \n","  \n","# Floating point models of the qat_model_nbit, without QuantWrappers\n","float_model_nbit = dequantize_model(qat_model_nbit)\n","\n","print(int_model_nbit)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jh2NGspeoq_I"},"outputs":[],"source":["from src.quant_conversion import print_features\n","\n","# Select a sample data to see the features of it\n","sample_data, _ = audio_processor.get_data_from_file(\n","    audio_processor.data_index['testing'][0], BACKGROUND_FREQUENCY,\n","    BACKGROUND_VOLUME_RANGE, TIME_SHIFT_SAMPLE, 'testing')\n","\n","print(\"=\" * 80)\n","print(\"Features from Quantized QAT Model\")\n","print(\"-\" * 80)\n","print_features(sample_data, int_model_nbit, 'Quantized QAT Model')\n","print()\n","print(\"=\" * 80)\n","print(\"Features from Model fp32\")\n","print(\"-\" * 80)\n","print_features(sample_data, model_fp32, \"Model fp32\")"]},{"cell_type":"markdown","metadata":{"id":"TMm7grfnoq_I"},"source":["### Compare the Performance Between Integer Models from Float/Quantized-Aware Finetuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHJaISbYoq_J"},"outputs":[],"source":["from src.quant_conversion import compare_model, compare_model_mse\n","\n","# Compare differences in predictions\n","# QAT trained floating point model vs. integer model converted from the QAT model \n","# Percentage of same predictions shows how \"quantization aware\" the float point model is \n","_ = compare_model(test_loader, float_model_nbit, int_model_nbit)\n","_ = compare_model_mse(test_loader, float_model_nbit, int_model_nbit)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNikQddjoq_J"},"outputs":[],"source":["from src.quant_conversion import compare_model, compare_model_mse\n","\n","# Float32 model vs. integer model converted from the float32 model using post training quantization\n","_ = compare_model(test_loader, model_fp32, post_quant_model)\n","_ = compare_model_mse(test_loader, model_fp32, post_quant_model)"]},{"cell_type":"code","source":["def report_stuff(bits, original_model):\n","    qat_accs = []\n","    ptq_accs = []\n","    for bit in bits:\n","        current_model = copy.deepcopy(original_model)\n","        # Settings for activations quantization: n-bit asymmetric quantization\n","        a_qconfig = QConfig(quant_bits=bit, is_symmetric=False)\n","        # Settings for weights quantization: n-bit symmetric quantization\n","        w_qconfig = QConfig(quant_bits=bit, is_symmetric=True)\n","        # Settings for bias quantization: n-bit symmetric quantization\n","        b_qconfig = QConfig(quant_bits=bit, is_symmetric=True)\n","        qat_model_nbit = quantize_model(current_model, a_qconfig=a_qconfig, w_qconfig=w_qconfig, b_qconfig=b_qconfig)\n","        verbose = False\n","        log_interval = 100\n","        num_batches = len(train_loader)\n","        n_epoch = 30\n","        print(f'#batches: {num_batches} \\n#epochs: {n_epoch} \\n#total training steps: {num_batches * n_epoch}')\n","\n","        # Create optimizer\n","        optimizer_quant = create_optimizer(model=qat_model_nbit, learning_rate=0.001)\n","        print(optimizer_quant.state_dict())\n","\n","        checkpoint_path = os.path.join(TORCH_DIR, \"quant_checkpoint\" + str(bit) + \".pt\")\n","        qat_model_nbit.to(device)\n","        run_training(\n","            model=qat_model_nbit, data_loaders=data_loaders, \n","            n_epoch=10, log_interval=log_interval, \n","            optimizer=optimizer_quant, scheduler=None, \n","            resume=False,\n","            checkpoint_path=checkpoint_path,\n","            verbose=verbose\n","        )\n","        # Quantized integer model of qat_model_nbit (quantized aware finetuning model)\n","        int_model_nbit = convert_to_int(\n","            qat_model_nbit, bit, dtype=torch.int32) \n","            \n","        # Post quantized model of model_fp32 (full-precision finetuned model)\n","        post_quant_model = convert_to_int(\n","            current_model, bit, dtype=torch.int32) \n","        _, qat_acc, ptq_acc = compare_model(test_loader, int_model_nbit, post_quant_model)\n","        print(qat_acc, ptq_acc)\n","        qat_accs.append(qat_acc)\n","        ptq_accs.append(ptq_acc)\n","    return qat_accs, ptq_accs\n","        "],"metadata":{"id":"rT0Xz-nQ-S7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from src.quant import *\n","from src.quant_conversion import *\n","from src.train_val_test_utils import *\n","a, b = report_stuff([2, 4, 6, 8], model_fp32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["233c2cf102d447608b5de494ac044d45","e4129003197c43dd99db29b2f2d83fce","266bb681a1d341bd85fc8a6ee8c48c5f","acaee60ea8104e6fa603dc824e8a9b12","78467fb71c36410981ed88ade61322df","52eccfde78e04c7e8e0c7e28da466b70","c26b50ada82b486bb03897f26fe8bef7","252ade71ba61485e9c6ee4b5b5d8c949","0d7da99901b24a439a2e6d9b46bb04eb","d65084f122de40cf82e9f743463b8e9a","cd46809d31da458d90dfea5fbf1c55cd","2614dd9a872244d7bda7f8564406813d","ba72dcb2bf5447fe8a6492b47b84cd47","145043e7683a4f5d8ec97c60cc1c41d4","2f82f3e7e3d147fa80209697f778dd26","fbf27535414e4dc3be463d2b171f1c04","ba459d4f95624705a41a6ce0b8986b92","e0698c51d06048f093985d80e256c33f","b138e8211f5d4ea29536b8aa015a0cf5","c0f77aa802eb4cc7bce84e26250a8803","e81b986588ea4723a18189fd005730cf","95d8d73e7d23463381dc040b9d1b1761","104a0c9b7bf1409f993ca0bbe1a9fe79","2aee6af23bc24aac8772a3f5162586f2","c3129d24669e461289f922c7989a9064","33b7d8344fb943d1aa66687c69948a70","f11b8f9dea584e8fbae5da2615cd3b66","b92ccad410b64d14860b4e19633f1460","194ad36a3ff043cfad51160a8760298b","3ead3b3d33f84102ba764ed8a830dc98","6ba04c0074714d5b965d7d281aa6b895","50d1fafb53ea4cd1858ae5af70e44dac","29342faa168140f2b368989b9e17c9be","68d22e713ca2456d8c8fbef987aaa3a5","5caf64a8f1a04751b076c0eff8037940","8e9abc0346c54cbc9247f4b7901f8d62","2056d262d766491689a90b22ef499cac","5d3a144dbdc04683903ba1f0c82d4a16","33180f26bbec4691861f6fe84ffb506a","90d208ba08c541108b0abb74e22e2faa","0febe2acd485404f9a8fd176453d9c0f","93fafd8267904c54ad41bfab1e00784d","36c3ae31c4cc413aa8e3755cf2df9cec","653ea7c9673b405bb344b59984dafc2e"]},"id":"TVHSK2Lhe8Jo","executionInfo":{"status":"ok","timestamp":1647158679755,"user_tz":240,"elapsed":3945718,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"f49f75b7-ae9a-42fc-d587-717821a04914"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["#batches: 106 \n","#epochs: 30 \n","#total training steps: 3180\n","{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'params': [0, 1, 2, 3]}]}\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"233c2cf102d447608b5de494ac044d45"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Acc Epoch 1 = 16.99%, Val Acc Epoch 1 = 16.35%, Train loss = 1.838\n","Train Acc Epoch 2 = 17.04%, Val Acc Epoch 2 = 16.28%, Train loss = 2.119\n","Train Acc Epoch 3 = 16.87%, Val Acc Epoch 3 = 17.1%, Train loss = 2.432\n","Train Acc Epoch 4 = 17.0%, Val Acc Epoch 4 = 16.58%, Train loss = 2.719\n","Train Acc Epoch 5 = 17.51%, Val Acc Epoch 5 = 16.35%, Train loss = 3.093\n","Train Acc Epoch 6 = 17.23%, Val Acc Epoch 6 = 17.7%, Train loss = 3.322\n","Train Acc Epoch 7 = 17.04%, Val Acc Epoch 7 = 17.25%, Train loss = 3.622\n","Train Acc Epoch 8 = 17.27%, Val Acc Epoch 8 = 16.65%, Train loss = 4.023\n","Train Acc Epoch 9 = 17.35%, Val Acc Epoch 9 = 18.15%, Train loss = 4.232\n","Train Acc Epoch 10 = 17.25%, Val Acc Epoch 10 = 17.33%, Train loss = 4.287\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: conv QuantWrapper(\n","  (module): Conv2d(1, 8, kernel_size=(10, 8), stride=(2, 2), padding=(5, 3))\n","\t(activation): quant_bits=2, quant_mode=asymmetric, prev_scale=8.502604484558105, prev_zeropoint=-0.0, prev_min=0.0, prev_max=25.5078125  \n","\t(weight): quant_bits=2, quant_mode=symmetric, prev_scale=0.9867647886276245, prev_zeropoint=0, prev_min=-1.973529577255249, prev_max=0.9867647886276245  \n","\t(bias): quant_bits=2, quant_mode=symmetric, prev_scale=1.156434178352356, prev_zeropoint=0, prev_min=-2.312868356704712, prev_max=1.156434178352356  \n",")\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","Staying the same: fc QuantWrapper(\n","  (module): Linear(in_features=4000, out_features=4, bias=True)\n","\t(activation): quant_bits=2, quant_mode=asymmetric, prev_scale=43.9760856628418, prev_zeropoint=-0.0, prev_min=0.0, prev_max=131.92825317382812  \n","\t(weight): quant_bits=2, quant_mode=symmetric, prev_scale=0.333698570728302, prev_zeropoint=0, prev_min=-0.333698570728302, prev_max=0.333698570728302  \n","\t(bias): quant_bits=2, quant_mode=symmetric, prev_scale=0.037671804428100586, prev_zeropoint=0, prev_min=0.0, prev_max=0.037671804428100586  \n",")\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","The models have 88.962% same predictions, \n","Model1 predicts 23.173% of the samples correctly, \n","Model2 predicts 24.123% of the samples correctly\n","0.23172514619883042 0.2412280701754386\n","#batches: 106 \n","#epochs: 30 \n","#total training steps: 3180\n","{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'params': [0, 1, 2, 3]}]}\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2614dd9a872244d7bda7f8564406813d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Acc Epoch 1 = 87.47%, Val Acc Epoch 1 = 88.15%, Train loss = 0.499\n","Train Acc Epoch 2 = 87.67%, Val Acc Epoch 2 = 88.37%, Train loss = 0.552\n","Train Acc Epoch 3 = 87.61%, Val Acc Epoch 3 = 87.77%, Train loss = 0.573\n","Train Acc Epoch 4 = 87.36%, Val Acc Epoch 4 = 89.2%, Train loss = 0.526\n","Train Acc Epoch 5 = 87.86%, Val Acc Epoch 5 = 88.3%, Train loss = 0.468\n","Train Acc Epoch 6 = 87.73%, Val Acc Epoch 6 = 88.3%, Train loss = 0.441\n","Train Acc Epoch 7 = 87.87%, Val Acc Epoch 7 = 88.45%, Train loss = 0.41\n","Train Acc Epoch 8 = 87.76%, Val Acc Epoch 8 = 87.85%, Train loss = 0.453\n","Train Acc Epoch 9 = 88.0%, Val Acc Epoch 9 = 88.22%, Train loss = 0.417\n","Train Acc Epoch 10 = 88.04%, Val Acc Epoch 10 = 88.52%, Train loss = 0.409\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: conv QuantWrapper(\n","  (module): Conv2d(1, 8, kernel_size=(10, 8), stride=(2, 2), padding=(5, 3))\n","\t(activation): quant_bits=4, quant_mode=asymmetric, prev_scale=1.7005208730697632, prev_zeropoint=-0.0, prev_min=0.0, prev_max=25.5078125  \n","\t(weight): quant_bits=4, quant_mode=symmetric, prev_scale=0.08424583822488785, prev_zeropoint=0, prev_min=-0.6739667057991028, prev_max=0.5897208452224731  \n","\t(bias): quant_bits=4, quant_mode=symmetric, prev_scale=0.02715996839106083, prev_zeropoint=0, prev_min=-0.21727974712848663, prev_max=0.19011977314949036  \n",")\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","Staying the same: fc QuantWrapper(\n","  (module): Linear(in_features=4000, out_features=4, bias=True)\n","\t(activation): quant_bits=4, quant_mode=asymmetric, prev_scale=1.9720790386199951, prev_zeropoint=-0.0, prev_min=0.0, prev_max=29.58118438720703  \n","\t(weight): quant_bits=4, quant_mode=symmetric, prev_scale=0.006878363434225321, prev_zeropoint=0, prev_min=-0.055026907473802567, prev_max=0.048148542642593384  \n","\t(bias): quant_bits=4, quant_mode=symmetric, prev_scale=0.18977315723896027, prev_zeropoint=0, prev_min=-0.569319486618042, prev_max=1.3284120559692383  \n",")\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","The models have 95.541% same predictions, \n","Model1 predicts 87.281% of the samples correctly, \n","Model2 predicts 87.208% of the samples correctly\n","0.8728070175438597 0.8720760233918129\n","#batches: 106 \n","#epochs: 30 \n","#total training steps: 3180\n","{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'params': [0, 1, 2, 3]}]}\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"104a0c9b7bf1409f993ca0bbe1a9fe79"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Acc Epoch 1 = 89.05%, Val Acc Epoch 1 = 89.35%, Train loss = 0.409\n","Train Acc Epoch 2 = 88.75%, Val Acc Epoch 2 = 88.07%, Train loss = 0.473\n","Train Acc Epoch 3 = 89.01%, Val Acc Epoch 3 = 88.52%, Train loss = 0.525\n","Train Acc Epoch 4 = 88.49%, Val Acc Epoch 4 = 88.67%, Train loss = 0.575\n","Train Acc Epoch 5 = 88.75%, Val Acc Epoch 5 = 87.7%, Train loss = 0.655\n","Train Acc Epoch 6 = 88.59%, Val Acc Epoch 6 = 88.3%, Train loss = 0.606\n","Train Acc Epoch 7 = 88.66%, Val Acc Epoch 7 = 89.35%, Train loss = 0.621\n","Train Acc Epoch 8 = 88.45%, Val Acc Epoch 8 = 88.9%, Train loss = 0.673\n","Train Acc Epoch 9 = 88.79%, Val Acc Epoch 9 = 88.15%, Train loss = 0.755\n","Train Acc Epoch 10 = 88.59%, Val Acc Epoch 10 = 88.6%, Train loss = 0.755\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: conv QuantWrapper(\n","  (module): Conv2d(1, 8, kernel_size=(10, 8), stride=(2, 2), padding=(5, 3))\n","\t(activation): quant_bits=6, quant_mode=asymmetric, prev_scale=0.4048859477043152, prev_zeropoint=-0.0, prev_min=0.0, prev_max=25.5078125  \n","\t(weight): quant_bits=6, quant_mode=symmetric, prev_scale=0.01315946877002716, prev_zeropoint=0, prev_min=-0.42110300064086914, prev_max=0.4079435467720032  \n","\t(bias): quant_bits=6, quant_mode=symmetric, prev_scale=0.004146642982959747, prev_zeropoint=0, prev_min=-0.13269257545471191, prev_max=0.12854593992233276  \n",")\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","Staying the same: fc QuantWrapper(\n","  (module): Linear(in_features=4000, out_features=4, bias=True)\n","\t(activation): quant_bits=6, quant_mode=asymmetric, prev_scale=0.31859374046325684, prev_zeropoint=-0.0, prev_min=0.0, prev_max=20.0714054107666  \n","\t(weight): quant_bits=6, quant_mode=symmetric, prev_scale=0.009147330187261105, prev_zeropoint=0, prev_min=-0.2195359170436859, prev_max=0.28356724977493286  \n","\t(bias): quant_bits=6, quant_mode=symmetric, prev_scale=0.032734520733356476, prev_zeropoint=0, prev_min=-0.36007973551750183, prev_max=1.0147701501846313  \n",")\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","The models have 99.123% same predictions, \n","Model1 predicts 88.523% of the samples correctly, \n","Model2 predicts 88.523% of the samples correctly\n","0.8852339181286549 0.8852339181286549\n","#batches: 106 \n","#epochs: 30 \n","#total training steps: 3180\n","{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'params': [0, 1, 2, 3]}]}\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d22e713ca2456d8c8fbef987aaa3a5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Acc Epoch 1 = 89.42%, Val Acc Epoch 1 = 90.85%, Train loss = 0.355\n","Train Acc Epoch 2 = 89.72%, Val Acc Epoch 2 = 90.47%, Train loss = 0.357\n","Train Acc Epoch 3 = 89.57%, Val Acc Epoch 3 = 89.27%, Train loss = 0.353\n","Train Acc Epoch 4 = 89.31%, Val Acc Epoch 4 = 90.02%, Train loss = 0.344\n","Train Acc Epoch 5 = 89.47%, Val Acc Epoch 5 = 89.42%, Train loss = 0.353\n","Train Acc Epoch 6 = 89.92%, Val Acc Epoch 6 = 89.87%, Train loss = 0.353\n","Train Acc Epoch 7 = 89.55%, Val Acc Epoch 7 = 88.82%, Train loss = 0.349\n","Train Acc Epoch 8 = 89.37%, Val Acc Epoch 8 = 90.7%, Train loss = 0.357\n","Train Acc Epoch 9 = 89.98%, Val Acc Epoch 9 = 89.27%, Train loss = 0.355\n","Train Acc Epoch 10 = 89.6%, Val Acc Epoch 10 = 90.62%, Train loss = 0.356\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: conv QuantWrapper(\n","  (module): Conv2d(1, 8, kernel_size=(10, 8), stride=(2, 2), padding=(5, 3))\n","\t(activation): quant_bits=8, quant_mode=asymmetric, prev_scale=0.10003064572811127, prev_zeropoint=-0.0, prev_min=0.0, prev_max=25.5078125  \n","\t(weight): quant_bits=8, quant_mode=symmetric, prev_scale=0.0010084803216159344, prev_zeropoint=0, prev_min=-0.1290854811668396, prev_max=0.12807700037956238  \n","\t(bias): quant_bits=8, quant_mode=symmetric, prev_scale=0.001357046770863235, prev_zeropoint=0, prev_min=-0.17370198667049408, prev_max=0.17234493792057037  \n",")\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","Staying the same: fc QuantWrapper(\n","  (module): Linear(in_features=4000, out_features=4, bias=True)\n","\t(activation): quant_bits=8, quant_mode=asymmetric, prev_scale=0.022439084947109222, prev_zeropoint=-0.0, prev_min=0.0, prev_max=5.72196626663208  \n","\t(weight): quant_bits=8, quant_mode=symmetric, prev_scale=0.0026371122803539038, prev_zeropoint=0, prev_min=-0.26107412576675415, prev_max=0.3349132537841797  \n","\t(bias): quant_bits=8, quant_mode=symmetric, prev_scale=0.004205756820738316, prev_zeropoint=0, prev_min=-0.1976705640554428, prev_max=0.5341311097145081  \n",")\n","Staying the same: conv_reshape Reshape(output_shape=(-1, 1, 49, 40))\n","Staying the same: relu ReLU()\n","Staying the same: dropout Dropout(p=0.5, inplace=False)\n","Staying the same: fc_reshape Reshape(output_shape=(-1, 4000))\n","The models have 95.541% same predictions, \n","Model1 predicts 89.327% of the samples correctly, \n","Model2 predicts 87.354% of the samples correctly\n","0.8932748538011696 0.8735380116959064\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","bits = [2, 4, 6, 8]\n","qat = [0.23172514619883042, 0.8728070175438597, 0.8852339181286549, 0.8932748538011696]\n","ptq = [0.2412280701754386, 0.8720760233918129, 0.8852339181286549, 0.8735380116959064]\n","\n","plt.figure()\n","plt.plot(bits, qat, label=\"Quantization Aware Training\")\n","plt.plot(bits, ptq, label=\"Post Training Quantization\")\n","plt.title(\"Accuracy vs. Bit width\")\n","plt.xlabel(\"Number of bits\")\n","plt.ylabel(\"Test accuracy\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"7nHASEpup_8P","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1647186434424,"user_tz":240,"elapsed":755,"user":{"displayName":"Ethan Glaser","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09497163345803200296"}},"outputId":"d22cb3dc-71d7-404c-c254-b0f0e60e8536"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[""],"metadata":{"id":"oUWLHZ4R9C5h"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"5_quantization.ipynb","provenance":[]},"interpreter":{"hash":"eed6bdaff5cc743acd241b8f3fe4c5dc3266475018a66ac615ca19ad2f28387d"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"233c2cf102d447608b5de494ac044d45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4129003197c43dd99db29b2f2d83fce","IPY_MODEL_266bb681a1d341bd85fc8a6ee8c48c5f","IPY_MODEL_acaee60ea8104e6fa603dc824e8a9b12"],"layout":"IPY_MODEL_78467fb71c36410981ed88ade61322df"}},"e4129003197c43dd99db29b2f2d83fce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52eccfde78e04c7e8e0c7e28da466b70","placeholder":"​","style":"IPY_MODEL_c26b50ada82b486bb03897f26fe8bef7","value":"100%"}},"266bb681a1d341bd85fc8a6ee8c48c5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_252ade71ba61485e9c6ee4b5b5d8c949","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d7da99901b24a439a2e6d9b46bb04eb","value":10}},"acaee60ea8104e6fa603dc824e8a9b12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d65084f122de40cf82e9f743463b8e9a","placeholder":"​","style":"IPY_MODEL_cd46809d31da458d90dfea5fbf1c55cd","value":" 10/10 [16:27&lt;00:00, 98.70s/it]"}},"78467fb71c36410981ed88ade61322df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52eccfde78e04c7e8e0c7e28da466b70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c26b50ada82b486bb03897f26fe8bef7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"252ade71ba61485e9c6ee4b5b5d8c949":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d7da99901b24a439a2e6d9b46bb04eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d65084f122de40cf82e9f743463b8e9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd46809d31da458d90dfea5fbf1c55cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2614dd9a872244d7bda7f8564406813d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba72dcb2bf5447fe8a6492b47b84cd47","IPY_MODEL_145043e7683a4f5d8ec97c60cc1c41d4","IPY_MODEL_2f82f3e7e3d147fa80209697f778dd26"],"layout":"IPY_MODEL_fbf27535414e4dc3be463d2b171f1c04"}},"ba72dcb2bf5447fe8a6492b47b84cd47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba459d4f95624705a41a6ce0b8986b92","placeholder":"​","style":"IPY_MODEL_e0698c51d06048f093985d80e256c33f","value":"100%"}},"145043e7683a4f5d8ec97c60cc1c41d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b138e8211f5d4ea29536b8aa015a0cf5","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0f77aa802eb4cc7bce84e26250a8803","value":10}},"2f82f3e7e3d147fa80209697f778dd26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e81b986588ea4723a18189fd005730cf","placeholder":"​","style":"IPY_MODEL_95d8d73e7d23463381dc040b9d1b1761","value":" 10/10 [16:25&lt;00:00, 98.05s/it]"}},"fbf27535414e4dc3be463d2b171f1c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba459d4f95624705a41a6ce0b8986b92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0698c51d06048f093985d80e256c33f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b138e8211f5d4ea29536b8aa015a0cf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0f77aa802eb4cc7bce84e26250a8803":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e81b986588ea4723a18189fd005730cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95d8d73e7d23463381dc040b9d1b1761":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"104a0c9b7bf1409f993ca0bbe1a9fe79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2aee6af23bc24aac8772a3f5162586f2","IPY_MODEL_c3129d24669e461289f922c7989a9064","IPY_MODEL_33b7d8344fb943d1aa66687c69948a70"],"layout":"IPY_MODEL_f11b8f9dea584e8fbae5da2615cd3b66"}},"2aee6af23bc24aac8772a3f5162586f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b92ccad410b64d14860b4e19633f1460","placeholder":"​","style":"IPY_MODEL_194ad36a3ff043cfad51160a8760298b","value":"100%"}},"c3129d24669e461289f922c7989a9064":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ead3b3d33f84102ba764ed8a830dc98","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ba04c0074714d5b965d7d281aa6b895","value":10}},"33b7d8344fb943d1aa66687c69948a70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50d1fafb53ea4cd1858ae5af70e44dac","placeholder":"​","style":"IPY_MODEL_29342faa168140f2b368989b9e17c9be","value":" 10/10 [16:15&lt;00:00, 97.36s/it]"}},"f11b8f9dea584e8fbae5da2615cd3b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92ccad410b64d14860b4e19633f1460":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"194ad36a3ff043cfad51160a8760298b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ead3b3d33f84102ba764ed8a830dc98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ba04c0074714d5b965d7d281aa6b895":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50d1fafb53ea4cd1858ae5af70e44dac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29342faa168140f2b368989b9e17c9be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68d22e713ca2456d8c8fbef987aaa3a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5caf64a8f1a04751b076c0eff8037940","IPY_MODEL_8e9abc0346c54cbc9247f4b7901f8d62","IPY_MODEL_2056d262d766491689a90b22ef499cac"],"layout":"IPY_MODEL_5d3a144dbdc04683903ba1f0c82d4a16"}},"5caf64a8f1a04751b076c0eff8037940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33180f26bbec4691861f6fe84ffb506a","placeholder":"​","style":"IPY_MODEL_90d208ba08c541108b0abb74e22e2faa","value":"100%"}},"8e9abc0346c54cbc9247f4b7901f8d62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0febe2acd485404f9a8fd176453d9c0f","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93fafd8267904c54ad41bfab1e00784d","value":10}},"2056d262d766491689a90b22ef499cac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36c3ae31c4cc413aa8e3755cf2df9cec","placeholder":"​","style":"IPY_MODEL_653ea7c9673b405bb344b59984dafc2e","value":" 10/10 [16:13&lt;00:00, 97.33s/it]"}},"5d3a144dbdc04683903ba1f0c82d4a16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33180f26bbec4691861f6fe84ffb506a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90d208ba08c541108b0abb74e22e2faa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0febe2acd485404f9a8fd176453d9c0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93fafd8267904c54ad41bfab1e00784d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36c3ae31c4cc413aa8e3755cf2df9cec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"653ea7c9673b405bb344b59984dafc2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}